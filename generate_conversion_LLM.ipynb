{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ff9269-235a-4666-9d66-cf8e14ef0948",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "from openai import OpenAI\n",
    "from scipy.optimize import minimize\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31c9dd-ea71-4a0c-bae5-96ed071f0787",
   "metadata": {},
   "source": [
    "## generate the initial user's risk preference conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1057046d-75d6-4bae-892b-e072d7b0cb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=\"your GPT API KEY\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc8e37-fa65-4774-a285-f426c719af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ef6b6-6d27-438a-9476-9d64f2679c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY_CSV = 'survey_data/IR Stock Questionaires (Responses).xlsx'\n",
    "USER_JSON = 'summary_data/'\n",
    "STOCK_RAW_JSON = 'multi_assets_20251017.json'\n",
    "user_conversation_path = 'user_conversation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603e5bae-fb3f-43cd-b901-c83ee8320622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess():\n",
    "    survey_df = pd.read_excel(SURVEY_CSV)\n",
    "    with open(STOCK_RAW_JSON, 'r') as fb:\n",
    "        raw_data = json.load(fb)\n",
    "    return survey_df, raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1011d3e4-3944-4c37-97aa-e7f423b1e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_user_annotation(user_name):\n",
    "    user_json_list = os.listdir(USER_JSON)\n",
    "    user_json = None\n",
    "    for file_name in user_json_list:\n",
    "        if isinstance(file_name, str) and user_name in file_name:\n",
    "            user_json=file_name\n",
    "    if user_json:\n",
    "        print(f\"get user {user_name}'s run data\")\n",
    "        with open(os.path.join(USER_JSON, user_json), 'r') as fb:\n",
    "            run_data = json.load(fb)\n",
    "        return run_data\n",
    "    else:\n",
    "        print(f\"No any user's name is {user_name}, please check it again!\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17454a-1171-4a20-b7f4-d08d53b10f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df, raw_data = load_and_preprocess() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23f80a-e4aa-4993-83e9-baa894b1939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f569d72-306f-40cf-925b-939ce83b5631",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'Income': survey_df.columns[1],\n",
    "    'Liquidity': survey_df.columns[2],\n",
    "    'Assets': survey_df.columns[3],\n",
    "    'Years_Exp': survey_df.columns[4],\n",
    "    'Goals': survey_df.columns[5],\n",
    "    'Instruments': survey_df.columns[6],\n",
    "    'Risk_Attitude': survey_df.columns[7],\n",
    "    'Gender': survey_df.columns[8],\n",
    "    'Age': survey_df.columns[9],\n",
    "    'Occupation': survey_df.columns[10],\n",
    "    'Life_Stage': survey_df.columns[11],\n",
    "    'Expenditure': survey_df.columns[12],\n",
    "    'Decline_Reaction': survey_df.columns[13],\n",
    "    'Social_FOMO': survey_df.columns[14],\n",
    "    'Literacy': survey_df.columns[15],\n",
    "    'State': survey_df.columns[16],\n",
    "    'Emergency_Fund': survey_df.columns[17],\n",
    "    'Liabilities': survey_df.columns[18]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88937c-353f-477a-b7ff-5e6b533a10f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_drawdown(prices):\n",
    "    \"\"\"Compute maximum drawdown (peak-to-trough) within a 7-day window.\"\"\"\n",
    "    prices = np.array(prices)\n",
    "    if len(prices) < 2:\n",
    "        return 0.0\n",
    "    running_max = np.maximum.accumulate(prices)\n",
    "    drawdowns = (running_max - prices) / running_max\n",
    "    return np.max(drawdowns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3552442-bc1e-400c-b639-6bae8ac97585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_based_ranks(snapshot):\n",
    "    \"\"\"Generate global Return and Volatility rankings based on a market snapshot.\"\"\"\n",
    "    \n",
    "    # 7-day return ranking (high to low)\n",
    "    ret_rank = sorted(\n",
    "        snapshot.keys(),\n",
    "        key=lambda x: float(snapshot[x]['7d_ret'].strip('%')),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    # Volatility ranking (low to high; lower is safer)\n",
    "    vol_rank = sorted(\n",
    "        snapshot.keys(),\n",
    "        key=lambda x: float(snapshot[x]['vol'])\n",
    "    )\n",
    "    \n",
    "    return ret_rank, vol_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb48278c-2ee3-4409-9d83-35245b05b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detailed_onboarding_prompt(row, column_mapping):\n",
    "    # Construct a \"Question: Answer\" text block\n",
    "    survey_details = \"\"\n",
    "    for key, col_name in column_mapping.items():\n",
    "        question_text = col_name  # Original survey question text\n",
    "        answer_text = row[col_name]  # User's corresponding answer\n",
    "        survey_details += f\"Question: {question_text}\\nAnswer: {answer_text}\\n\\n\"\n",
    "\n",
    "    # Build the enhanced prompt\n",
    "    prompt = f\"\"\"\n",
    "Act as a Senior Financial Psychologist and Scene Director. Your goal is to simulate an 'Onboarding Interview' between a Professional Advisor and a Client.\n",
    "\n",
    "### [CLIENT'S TRUTH: SURVEY RESPONSES]\n",
    "This is the raw data collected from the client's initial survey. Use these details to anchor the client's personality, vocabulary, and financial anxiety.\n",
    "\n",
    "{survey_details}\n",
    "\n",
    "### [SIMULATION TASK]\n",
    "Conduct a high-fidelity, 4-turn dialogue (Advisor-Client pairs). \n",
    "1. **Turn 1 (Social & Background):** The Advisor introduces themselves and asks about the client's professional life and general situation. The Client responds, revealing their life stage and current mood.\n",
    "2. **Turn 2 (Financial Foundation):** The Advisor probes into assets, liabilities, and income stability. The Client discusses their financial 'safety net' (or lack thereof), reflecting their real-world constraints (like debt or low liquidity).\n",
    "3. **Turn 3 (Ambitions & Conflicts):** The Advisor asks about investment goals and experience. If the client is a \"Beginner\" but wants \"Active Trading,\" the Advisor must gently point out this risk, and the Client should explain their internal motivation (e.g., 'need to catch up' or 'FOMO').\n",
    "4. **Turn 4 (The Stress Test):** The Advisor simulates a market crash scenario based on the client's risk profile. The Client reveals their deepest fears and instinctive reactions to loss.\n",
    "\n",
    "### [SCENE CONSTRAINTS]\n",
    "- **No Scripted Language:** Avoid generic AI phrases. The Client should use first-person language (\"I feel...\", \"My debt is...\").\n",
    "- **Literacy Matching:** If the survey says the client is a 'Beginner', they must NOT use professional jargon. They should sound like a layperson.\n",
    "- **Hidden Signals:** Use the 'Emergency Fund' and 'Liabilities' data to color the client's level of confidence or desperation.\n",
    "- **Consistency:** Ensure the client's tone remains consistent with their 'Risk Attitude' and 'Decline Reaction'.\n",
    "\n",
    "### [OUTPUT FORMAT]\n",
    "Return ONLY a valid JSON array of objects, like this:\n",
    "[\n",
    "  {{\"role\": \"advisor\", \"content\": \"...\"}},\n",
    "  {{\"role\": \"user\", \"content\": \"...\"}}\n",
    "]\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a401c9-5d88-4183-aa59-d7bf06fa8aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_market_master_dict_enhanced(raw_data):\n",
    "    \"\"\"\n",
    "    Enhanced version: provides not only the conversational snapshot,\n",
    "    but also raw features for utility computation.\n",
    "    \"\"\"\n",
    "    tickers = [key.replace('_DAILY_LAST30D', '') for key in raw_data.keys()]\n",
    "    first_key = list(raw_data.keys())[0]\n",
    "    dates = [entry['date'] for entry in raw_data[first_key]]\n",
    "    daily_closes = {\n",
    "        k.replace('_DAILY_LAST30D', ''): [e['close'] for e in raw_data[k]]\n",
    "        for k in raw_data.keys()\n",
    "    }\n",
    "    \n",
    "    market_master = {}\n",
    "    for step in range(1, 24):\n",
    "        window_start, window_end = step - 1, step + 5\n",
    "        decision_date = dates[window_end + 1]\n",
    "        snapshot = {}\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            prices = daily_closes[ticker][window_start: window_end + 1]\n",
    "            daily_rets = np.diff(prices) / prices[:-1]\n",
    "            \n",
    "            # --- Core metric computation ---\n",
    "            mu = np.mean(daily_rets)       # Expected return\n",
    "            var = np.var(daily_rets)       # Return variance\n",
    "            mdd = calculate_max_drawdown(prices)  # Maximum drawdown\n",
    "            \n",
    "            snapshot[ticker] = {\n",
    "                \"mu\": mu,\n",
    "                \"var\": var,\n",
    "                \"mdd\": mdd,  # Raw floating-point values used for utility formula\n",
    "                \"7d_ret\": f\"{(prices[-1] / prices[0] - 1):.2%}\",\n",
    "                \"vol\": f\"{np.std(daily_rets):.4f}\",\n",
    "                \"current_price\": f\"${prices[-1]:.2f}\",\n",
    "                \"price_trend\": [f\"${p:.2f}\" for p in prices],\n",
    "            }\n",
    "        market_master[f\"step_{step}\"] = {\n",
    "            \"date\": decision_date,\n",
    "            \"snapshot\": snapshot,\n",
    "        }\n",
    "    return market_master, tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b526d0-7bb8-4e6f-a5fc-0b08727b7608",
   "metadata": {},
   "source": [
    "## Phase 1 offline optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419e96c-8f5d-4bba-b06f-eec859935b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traditional optimization\n",
    "def calibrate_user_parameters(run_data, market_master, tickers):\n",
    "    \"\"\"\n",
    "    Phase 1: Inverse Optimization\n",
    "    Estimate the user's Financial DNA parameters via Maximum Likelihood Estimation (MLE)\n",
    "    \"\"\"\n",
    "    ticker_to_idx = {t: i for i, t in enumerate(tickers)}\n",
    "    trajectory = []\n",
    "\n",
    "    # 1. Prepare training data: align 23-step user choices with corresponding market states\n",
    "    for s in run_data['selections']:\n",
    "        step_idx = s['step']\n",
    "        if step_idx > 23:\n",
    "            continue  # Only process the first 23 steps\n",
    "        \n",
    "        snap = market_master[f\"step_{step_idx}\"][\"snapshot\"]\n",
    "        mus = np.array([snap[t]['mu'] for t in tickers])\n",
    "        vars_ = np.array([snap[t]['var'] for t in tickers])\n",
    "        mdds = np.array([snap[t]['mdd'] for t in tickers])\n",
    "        chosen_idx = ticker_to_idx[s['asset']]\n",
    "        \n",
    "        trajectory.append({\n",
    "            'mus': mus,\n",
    "            'vars': vars_,\n",
    "            'dds': mdds,\n",
    "            'chosen_idx': chosen_idx\n",
    "        })\n",
    "\n",
    "    # 2. Define the Negative Log-Likelihood (NLL) loss function\n",
    "    def nll_loss(params):\n",
    "        lam, gamma = params\n",
    "        loss = 0\n",
    "        for step in trajectory:\n",
    "            # Utility formula: U = mu - lambda * var - gamma * mdd\n",
    "            utilities = step['mus'] - lam * step['vars'] - gamma * step['dds']\n",
    "            \n",
    "            # Softmax probability\n",
    "            max_u = np.max(utilities)\n",
    "            exp_u = np.exp(utilities - max_u)\n",
    "            probs = exp_u / np.sum(exp_u)\n",
    "            \n",
    "            loss -= np.log(probs[step['chosen_idx']] + 1e-10)\n",
    "        return loss\n",
    "\n",
    "    # 3. Solve the optimization problem\n",
    "    res = minimize(\n",
    "        nll_loss,\n",
    "        x0=[5.0, 0.5],\n",
    "        bounds=[(0, None), (0, None)],\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "\n",
    "    (lambda_i, gamma_i) = (\n",
    "        (res.x[0], res.x[1]) if res.success else (5.0, 5.0)\n",
    "    )\n",
    "\n",
    "    hit_rate = evaluate_dna_hit_rate(lambda_i, gamma_i, trajectory)\n",
    "    return lambda_i, gamma_i, hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037883bf-605e-4af5-b466-5c5b7c1eb206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardized optimization\n",
    "\n",
    "def calibrate_user_dna_standardized(run_data, market_master, tickers):\n",
    "    ticker_to_idx = {t: i for i, t in enumerate(tickers)}\n",
    "    trajectory = []\n",
    "\n",
    "    for s in run_data['selections']:\n",
    "        step_idx = s['step']\n",
    "        if step_idx > 23:\n",
    "            continue\n",
    "        \n",
    "        snap = market_master[f\"step_{step_idx}\"][\"snapshot\"]\n",
    "        \n",
    "        # Extract raw feature vectors\n",
    "        mus = np.array([snap[t]['mu'] for t in tickers])\n",
    "        vars_ = np.array([snap[t]['var'] for t in tickers])\n",
    "        mdds = np.array([snap[t]['mdd'] for t in tickers])\n",
    "        \n",
    "        # --- Core improvement: cross-sectional standardization (Z-score) ---\n",
    "        # Ensures the three feature groups contribute equally in variance\n",
    "        # before entering the Softmax\n",
    "        def scale(x):\n",
    "            std = np.std(x)\n",
    "            return (x - np.mean(x)) / (std if std > 1e-9 else 1.0)\n",
    "\n",
    "        trajectory.append({\n",
    "            'mus': scale(mus),\n",
    "            'vars': scale(vars_),\n",
    "            'dds': scale(mdds),\n",
    "            'chosen_idx': ticker_to_idx[s['asset']]\n",
    "        })\n",
    "\n",
    "    def nll_loss(params):\n",
    "        lam, gamma = params\n",
    "        loss = 0\n",
    "        for step in trajectory:\n",
    "            # Here lambda and gamma represent relative weight ratios\n",
    "            # across standardized indicators\n",
    "            utilities = step['mus'] - lam * step['vars'] - gamma * step['dds']\n",
    "            \n",
    "            # Numerical stability handling\n",
    "            max_u = np.max(utilities)\n",
    "            exp_u = np.exp(utilities - max_u)\n",
    "            probs = exp_u / (np.sum(exp_u) + 1e-10)\n",
    "            \n",
    "            loss -= np.log(probs[step['chosen_idx']] + 1e-10)\n",
    "        \n",
    "        # L2 regularization to prevent parameter drift in extreme cases\n",
    "        reg = 0.01 * (lam**2 + gamma**2)\n",
    "        return loss + reg\n",
    "\n",
    "    # Use more reasonable initialization and bounds\n",
    "    res = minimize(\n",
    "        nll_loss,\n",
    "        x0=[1.0, 1.0],\n",
    "        bounds=[(0, 20), (0, 20)],\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "\n",
    "    (lambda_i, gamma_i) = (\n",
    "        (res.x[0], res.x[1]) if res.success else (1.0, 1.0)\n",
    "    )\n",
    "\n",
    "    hit_rate = evaluate_dna_hit_rate(lambda_i, gamma_i, trajectory)\n",
    "    return lambda_i, gamma_i, hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd8867b-c4be-4686-95cf-04b8622a30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized optimization\n",
    "def calibrate_user_dna_regularized(run_data, market_master, tickers):\n",
    "    ticker_to_idx = {t: i for i, t in enumerate(tickers)}\n",
    "    trajectory = []\n",
    "\n",
    "    for s in run_data['selections']:\n",
    "        step_idx = s['step']\n",
    "        if step_idx > 23:\n",
    "            continue\n",
    "        snap = market_master[f\"step_{step_idx}\"][\"snapshot\"]\n",
    "        trajectory.append({\n",
    "            'mus': np.array([snap[t]['mu'] for t in tickers]),\n",
    "            'vars': np.array([snap[t]['var'] for t in tickers]),\n",
    "            'dds': np.array([snap[t]['mdd'] for t in tickers]),\n",
    "            'chosen_idx': ticker_to_idx[s['asset']]\n",
    "        })\n",
    "\n",
    "    def nll_loss(params):\n",
    "        lam, gamma = params\n",
    "        loss = 0\n",
    "        for step in trajectory:\n",
    "            # Original utility formula\n",
    "            utilities = step['mus'] - lam * step['vars'] - gamma * step['dds']\n",
    "            max_u = np.max(utilities)\n",
    "            exp_u = np.exp(utilities - max_u)\n",
    "            probs = exp_u / (np.sum(exp_u) + 1e-10)\n",
    "            loss -= np.log(probs[step['chosen_idx']] + 1e-10)\n",
    "        \n",
    "        # Core improvement: asymmetric regularization\n",
    "        # Since var is very small (~10^-5), lambda requires weaker penalty\n",
    "        # Since mdd is relatively larger (~10^-2), gamma requires stronger penalty\n",
    "        reg = 0.001 * lam**2 + 0.1 * gamma**2 \n",
    "        return loss + reg\n",
    "\n",
    "    res = minimize(\n",
    "        nll_loss,\n",
    "        x0=[10.0, 10.0],\n",
    "        bounds=[(0, 1000), (0, 200)],\n",
    "        method='L-BFGS-B'\n",
    "    )\n",
    "\n",
    "    lambda_i, gamma_i = res.x[0], res.x[1]\n",
    "    hit_rate = evaluate_dna_hit_rate(lambda_i, gamma_i, trajectory)\n",
    "    return lambda_i, gamma_i, hit_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1ec57-b708-44ba-853d-b894399aff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dna_hit_rate(lambda_i, gamma_i, trajectory):\n",
    "    \"\"\"\n",
    "    诊断工具：计算拟合出的 DNA 在 23 步中能多大程度预测用户的真实选择\n",
    "    \"\"\"\n",
    "    hits = 0\n",
    "    for step in trajectory:\n",
    "        # 计算效用值\n",
    "        u = step['mus'] - lambda_i * step['vars'] - gamma_i * step['dds']\n",
    "        # 预测排名第一的索引\n",
    "        pred_idx = np.argmax(u)\n",
    "        if pred_idx == step['chosen_idx']:\n",
    "            hits += 1\n",
    "    return hits / len(trajectory)\n",
    "\n",
    "# 使用示例\n",
    "# hit_rate = evaluate_dna_hit_rate(res.x[0], res.x[1], trajectory)\n",
    "# print(f\"DNA Prediction Accuracy: {hit_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a705af-ef4c-4a15-ae51-ef65d211b8d2",
   "metadata": {},
   "source": [
    "## phase 2 Real-time rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7145268d-1bc2-4101-b5d1-0e148d8adc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_ground_truth(snapshot, lam, gam):\n",
    "    \"\"\"\n",
    "    Phase 2: Compute the ground-truth ranking for the current step\n",
    "    based on calibrated parameters.\n",
    "    \"\"\"\n",
    "    scores = {}\n",
    "    for ticker, data in snapshot.items():\n",
    "        # Utility formula: U = mu - lambda * var - gamma * mdd\n",
    "        u = data['mu'] - lam * data['var'] - gam * data['mdd']\n",
    "        scores[ticker] = u\n",
    "    \n",
    "    # Return ranking from highest to lowest utility\n",
    "    return sorted(scores.keys(), key=lambda x: scores[x], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcfad3-5d9a-4aaf-834c-8b7e801248a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Build market snapshots and feature libraries\n",
    "market_master_dict, tickers = build_market_master_dict_enhanced(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeb1655-9f19-4823-99bb-54a79d13d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_master_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa3da9a-306f-4098-a5be-53255ae4a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7166acf8-62af-4449-943d-dc0ce8f19b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multi_advisor_step_prompt(step_idx, history, snapshot, chosen_asset, feedback, ranks, lambda_i, gamma_i):\n",
    "    # Constructing market display text\n",
    "    market_elements = []\n",
    "    for tk, v in snapshot.items():\n",
    "        trend_str = f\"{v['price_trend'][0]} -> {v['price_trend'][-1]}\"\n",
    "        market_elements.append(\n",
    "            f\"- {tk}: 7D Ret: {v['7d_ret']}, Var: {v['var']:.6f}, \"\n",
    "            f\"Max Drawdown: {v['mdd']:.2%}, Trend: ({trend_str})\"\n",
    "        )\n",
    "    market_text = \"\\n\".join(market_elements)\n",
    "    \n",
    "    # Dynamically construct Advisor 1's internal personality cues (without revealing them to the User).\n",
    "    dna_insight = []\n",
    "    if lambda_i > 0.1: dna_insight.append(\"User dislikes price volatility.\")\n",
    "    if gamma_i > 0.1: dna_insight.append(\"User is extremely averse to peak-to-trough drawdowns.\")\n",
    "    insight_text = \" \".join(dna_insight)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "### [SYSTEM ROLE]\n",
    "You are simulating Step {step_idx}/23 of a financial advisory session. \n",
    "Act as 3 specialized Advisors and a Client.\n",
    "\n",
    "### [EXPERT PERSONAS]\n",
    "1. **Advisor 1 (Rationalist)**: Lead professional. Your advice follows a Mean-Variance-Drawdown utility model. You recommend the most balanced choice for the user's specific DNA.\n",
    "2. **Advisor 2 (Momentum Hunter)**: Trend-focused. You chase the highest 7-day average returns (μ).\n",
    "3. **Advisor 3 (Safety Manager)**: Risk-averse. You prioritize capital preservation (min σ² and Drawdown).\n",
    "\n",
    "### [STRICT COMMUNICATION CONSTRAINTS]\n",
    "- **NO MATHEMATICAL LEAKAGE**: Never mention \"Utility functions\", \"Lambda/Gamma\", \"Z-scores\", or formulas like \"U = μ - λσ²\".\n",
    "- **PROFESSIONAL TRANSLATION**: Convert data into advice. \n",
    "    - *Poor*: \"Your Gamma is high, so I pick X.\"\n",
    "    - *Better*: \"Given your preference for avoiding sharp market dips, I recommend X for its superior downside protection.\"\n",
    "\n",
    "### [CONTEXT]\n",
    "- **Advisor 1's Internal Insight**: {insight_text}\n",
    "- **Market Snapshot**:\n",
    "{market_text}\n",
    "- **Last Round Feedback**: {feedback}\n",
    "- **History**: {json.dumps(history[-4:], indent=2)}\n",
    "\n",
    "### [INTERNAL GROUND TRUTH (For Advisor 1-3 Reference)]\n",
    "- Utility Rank (Ideal for this user): {ranks['utility']}\n",
    "- Momentum Rank: {ranks['return']}\n",
    "- Safety Rank: {ranks['volatility']}\n",
    "\n",
    "### [TASK]\n",
    "1. **Panel Discussion**: Each advisor gives a 1-2 sentence recommendation. \n",
    "   - **Advisor 1** must advocate for **{ranks['utility'][0]}**. Explain why it's the most rational choice without using math.\n",
    "2. **The User Decision**: The client MUST finalize the choice as **{chosen_asset}**. \n",
    "   - If {chosen_asset} != Advisor 1's top pick, the user must provide a subjective reason (e.g., \"I'm feeling aggressive today\" or \"I'm ignoring the risk Advisor 3 mentioned\").\n",
    "\n",
    "### [OUTPUT FORMAT - JSON]\n",
    "Return ONLY a JSON object:\n",
    "{{\n",
    "  \"advisor_1_msg\": \"...\",\n",
    "  \"advisor_2_msg\": \"...\",\n",
    "  \"advisor_3_msg\": \"...\",\n",
    "  \"user_msg\": \"...\",\n",
    "  \"advisor_rankings\": {{\n",
    "      \"utility_expert\": {json.dumps(ranks['utility'])},\n",
    "      \"momentum_expert\": {json.dumps(ranks['return'])},\n",
    "      \"safety_expert\": {json.dumps(ranks['volatility'])}\n",
    "  }}\n",
    "}}\n",
    "\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ef7fc-d489-402e-adb0-283606d6004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_safely(response_str):\n",
    "    \"\"\"\n",
    "    Clean and safely parse a JSON string returned by an LLM.\n",
    "    \"\"\"\n",
    "    # 1. Try direct parsing (if the response is already clean)\n",
    "    try:\n",
    "        return json.loads(response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    # 2. Remove Markdown code block markers\n",
    "    # Match ```json ... ``` or ``` ... ```\n",
    "    clean_str = re.sub(r'```json\\s*|```\\s*', '', response_str).strip()\n",
    "    \n",
    "    # 3. If still failing, attempt to extract the first {...} or [...] block via regex\n",
    "    try:\n",
    "        match = re.search(r'(\\{.*\\}|\\[.*\\])', clean_str, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group(1))\n",
    "    except (json.JSONDecodeError, AttributeError):\n",
    "        pass\n",
    "\n",
    "    # 4. Raise error for debugging\n",
    "    print(f\"Failed to parse JSON. Raw response was: {response_str}\")\n",
    "    raise ValueError(\"LLM response is not a valid JSON format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53132025-b3dc-4a28-9644-400f4e4a50eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(user_input):\n",
    "    response = client.responses.create(\n",
    "        model=\"gpt-5.2-2025-12-11\",\n",
    "        input=user_input,\n",
    "        reasoning={\n",
    "            \"effort\": \"low\"\n",
    "        },\n",
    "        text={\n",
    "            \"verbosity\": \"low\"\n",
    "        }\n",
    "    )\n",
    "    return response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828f675-a86b-42f6-8845-982dd3bf667d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ground_truth_ranks(snapshot, tickers, lambda_i, gamma_i):\n",
    "    \"\"\"\n",
    "    Core transformation function:\n",
    "    Convert raw market snapshot into three standardized ground-truth rankings.\n",
    "    \"\"\"\n",
    "    # 1. Extract raw feature vectors\n",
    "    mus_raw = np.array([snapshot[tk]['mu'] for tk in tickers])\n",
    "    vars_raw = np.array([snapshot[tk]['var'] for tk in tickers])\n",
    "    mdds_raw = np.array([snapshot[tk]['mdd'] for tk in tickers])\n",
    "\n",
    "    # 2. Define internal cross-sectional standardization function\n",
    "    # (must match calibration logic exactly)\n",
    "    def cross_sectional_scale(x):\n",
    "        std = np.std(x)\n",
    "        if std < 1e-12:\n",
    "            return x - np.mean(x)\n",
    "        return (x - np.mean(x)) / std\n",
    "\n",
    "    # Apply standardization\n",
    "    mus_s = cross_sectional_scale(mus_raw)\n",
    "    vars_s = cross_sectional_scale(vars_raw)\n",
    "    mdds_s = cross_sectional_scale(mdds_raw)\n",
    "\n",
    "    # 3. Compute utility scores and ranking\n",
    "    # Utility function: U = mu_s - lambda * var_s - gamma * mdd_s\n",
    "    utility_scores = {\n",
    "        tickers[i]: mus_s[i] - lambda_i * vars_s[i] - gamma_i * mdds_s[i]\n",
    "        for i in range(len(tickers))\n",
    "    }\n",
    "    util_rank = sorted(\n",
    "        utility_scores.keys(),\n",
    "        key=lambda x: utility_scores[x],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    # 4. Compute momentum ranking (Momentum: based only on return mu)\n",
    "    momentum_rank = sorted(\n",
    "        tickers,\n",
    "        key=lambda x: snapshot[x]['mu'],\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    # 5. Compute safety ranking (Safety: penalize volatility and drawdown)\n",
    "    # For the current user, risk is the weighted sum of standardized risk terms\n",
    "    safety_scores = {\n",
    "        tickers[i]: lambda_i * vars_s[i] + gamma_i * mdds_s[i]\n",
    "        for i in range(len(tickers))\n",
    "    }\n",
    "    vol_rank = sorted(\n",
    "        safety_scores.keys(),\n",
    "        key=lambda x: safety_scores[x]\n",
    "    )  # Lower score indicates safer asset\n",
    "\n",
    "    return {\n",
    "        'utility': util_rank,\n",
    "        'return': momentum_rank,\n",
    "        'volatility': vol_rank\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce0ca22-c0db-48ea-a670-0efb384865a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversation(survey_df, user_conversation_path, start_index=0):\n",
    "    \n",
    "    for index, row in survey_df.iterrows():\n",
    "        if index < start_index:\n",
    "            continue\n",
    "        \n",
    "        # Each user corresponds to one run_data \n",
    "        # (assuming the mapping has already been handled)\n",
    "        user_name = row[\"Name\"]\n",
    "        user_id = f\"User_{index}\"\n",
    "\n",
    "        run_data = load_user_annotation(user_name)\n",
    "        if run_data:\n",
    "            # --- PHASE 1: Inverse optimization calibration (obtain global parameters for this user) ---\n",
    "            print(f\"Calibrating Financial DNA for {user_id}...\")\n",
    "            lambda_i, gamma_i, hit_rate = calibrate_user_dna_standardized(\n",
    "                run_data, market_master_dict, tickers\n",
    "            )\n",
    "            print(f\"Result -> Lambda: {lambda_i:.4f}, Gamma: {gamma_i:.4f}, Hit Rate: {hit_rate: .2%}\")\n",
    "\n",
    "            # 1. Onboarding (keep unchanged)\n",
    "            onboarding_prompt = generate_detailed_onboarding_prompt(row, column_mapping)\n",
    "            initial_response = get_response(onboarding_prompt)\n",
    "            history = parse_json_safely(initial_response)\n",
    "            \n",
    "            history.append({\n",
    "                \"role\": \"system\", \n",
    "                \"content\": \"The onboarding is complete. A panel of experts has joined.\"\n",
    "            })\n",
    "            \n",
    "            final_output = []\n",
    "            \n",
    "            # 2. Decision loop (Step 1–23)\n",
    "            for t in range(1, 24):\n",
    "                print(f\"conversation for step {t}......\")\n",
    "                step_market_info = market_master_dict[f\"step_{t}\"]\n",
    "                snapshot = step_market_info[\"snapshot\"]\n",
    "                \n",
    "                # --- Call core function to obtain rankings ---\n",
    "                ranks = get_ground_truth_ranks(snapshot, tickers, lambda_i, gamma_i)\n",
    "                \n",
    "                # Retrieve ground-truth selection and feedback\n",
    "                selection = next(s for s in run_data['selections'] if s['step'] == t)\n",
    "                chosen_asset = selection['asset']\n",
    "                \n",
    "                # Build feedback text\n",
    "                feedback = (\n",
    "                    f\"Last return: {selection['ret']:.2%}\" \n",
    "                    if t > 1 else \"First step.\"\n",
    "                )\n",
    "            \n",
    "                # Generate prompt and call LLM\n",
    "                prompt = generate_multi_advisor_step_prompt(\n",
    "                    t, history, snapshot, chosen_asset, feedback, ranks, lambda_i, gamma_i\n",
    "                )\n",
    "                raw_response = get_response(prompt)\n",
    "                \n",
    "                try:\n",
    "                    res = parse_json_safely(raw_response)\n",
    "                    \n",
    "                    step_entry = {\n",
    "                        \"step\": t,\n",
    "                        \"date\": step_market_info[\"date\"],\n",
    "                        \"calibrated_dna\": {\"lambda\": lambda_i, \"gamma\": gamma_i},\n",
    "                        \"market_snapshot\": snapshot,\n",
    "                        \"advisor_panel\": {\n",
    "                            \"utility_advisor\": {\n",
    "                                \"msg\": res['advisor_1_msg'], \n",
    "                                \"rank\": ranks['utility']\n",
    "                            },\n",
    "                            \"momentum_advisor\": {\n",
    "                                \"msg\": res['advisor_2_msg'], \n",
    "                                \"rank\": ranks['return']\n",
    "                            },\n",
    "                            \"safety_advisor\": {\n",
    "                                \"msg\": res['advisor_3_msg'], \n",
    "                                \"rank\": ranks['volatility']\n",
    "                            }\n",
    "                        },\n",
    "                        \"user_turn\": {\n",
    "                            \"msg\": res['user_msg'], \n",
    "                            \"choice\": chosen_asset\n",
    "                        }\n",
    "                    }\n",
    "                    \n",
    "                    # Update conversation history\n",
    "                    history_text = (\n",
    "                        f\"Panel Discussion - Advisor1: {res['advisor_1_msg']} \"\n",
    "                        f\"Advisor2: {res['advisor_2_msg']} \"\n",
    "                        f\"Advisor3: {res['advisor_3_msg']}\"\n",
    "                    )\n",
    "                    history.append({\"role\": \"advisor\", \"content\": history_text})\n",
    "                    history.append({\"role\": \"user\", \"content\": res['user_msg']})\n",
    "                    \n",
    "                    final_output.append(step_entry)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error at step {t}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            with open(\n",
    "                os.path.join(user_conversation_path, f\"{user_id}_conversation_history.json\"), \n",
    "                \"w\"\n",
    "            ) as f:\n",
    "                json.dump(history, f, indent=4)\n",
    "\n",
    "            with open(\n",
    "                os.path.join(user_conversation_path, f\"{user_id}_conversation_select.json\"), \n",
    "                \"w\"\n",
    "            ) as fb:\n",
    "                json.dump(final_output, fb, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef224291-2887-484d-b30a-5beb07c8a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_conversation(survey_df,user_conversation_path, start_index=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef1595b-69ac-4ead-b0db-f1f65273d726",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
