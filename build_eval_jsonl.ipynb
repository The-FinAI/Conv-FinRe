{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa212882-c66a-4c81-b84c-b034786f9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "from typing import List, Dict, Any, Tuple, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f89c7c-9133-4899-a943-db3f18ca90db",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKER = \"The onboarding is complete. A panel of experts has joined.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d15281-c4ce-4bf2-b4b2-d32843585fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path: str) -> Any:\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_jsonl(records: List[Dict[str, Any]], out_path: str) -> None:\n",
    "    os.makedirs(os.path.dirname(out_path), exist_ok=True) if os.path.dirname(out_path) else None\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as wf:\n",
    "        for r in records:\n",
    "            wf.write(json.dumps(r, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8161850-7e2d-4e39-9394-8207cb5464e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Conversation processing\n",
    "# -----------------------------\n",
    "def split_onboarding(history: List[Dict[str, Any]]) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Split onboarding vs post-onboarding by the system marker message.\n",
    "    \"\"\"\n",
    "    idx = None\n",
    "    for i, m in enumerate(history):\n",
    "        if m.get(\"role\") == \"system\" and MARKER in m.get(\"content\", \"\"):\n",
    "            idx = i\n",
    "            break\n",
    "    if idx is None:\n",
    "        raise ValueError(\"Onboarding marker not found in history.\")\n",
    "    onboarding = history[:idx]\n",
    "    post = history[idx + 1:]\n",
    "    return onboarding, post\n",
    "\n",
    "def slice_post_history_for_step(post: List[Dict[str, Any]], step_t: int) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Your post-history is stored as pairs per step:\n",
    "      advisor(step1), user(step1), advisor(step2), user(step2), ...\n",
    "    For sample at step t, include steps 1..t-1 -> first 2*(t-1) messages.\n",
    "    \"\"\"\n",
    "    n = 2 * (step_t - 1)\n",
    "    return post[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636bebd8-16ee-44c7-8343-5daa5dcda4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Market snapshot formatting\n",
    "# -----------------------------\n",
    "def _fmt_val(x: Any) -> str:\n",
    "    if x is None:\n",
    "        return \"NA\"\n",
    "    # keep floats readable\n",
    "    if isinstance(x, float):\n",
    "        return f\"{x:.6g}\"\n",
    "    return str(x)\n",
    "\n",
    "def format_market_snapshot(snapshot: Dict[str, Any], field_order: Optional[List[str]] = None) -> str:\n",
    "    \"\"\"\n",
    "    Convert market_snapshot dict -> compact readable text.\n",
    "\n",
    "    snapshot example: {\n",
    "      \"AAPL\": {\"mu\":..., \"var\":..., \"mdd\":..., \"7d_ret\":..., \"vol\":..., \"current_price\":..., \"price_trend\":...},\n",
    "      ...\n",
    "    }\n",
    "    \"\"\"\n",
    "    if field_order is None:\n",
    "        # choose a stable, interpretable order\n",
    "        field_order = [\"7d_ret\", \"vol\", \"mdd\", \"mu\", \"var\", \"current_price\", \"price_trend\"]\n",
    "\n",
    "    lines = []\n",
    "    for ticker in snapshot.keys():\n",
    "        info = snapshot[ticker] or {}\n",
    "        parts = []\n",
    "        for k in field_order:\n",
    "            if k in info:\n",
    "                parts.append(f\"{k}={_fmt_val(info.get(k))}\")\n",
    "        # if none of the ordered keys exist, dump keys compactly\n",
    "        if not parts:\n",
    "            parts = [f\"{k}={_fmt_val(v)}\" for k, v in info.items()]\n",
    "        lines.append(f\"{ticker}: \" + \", \".join(parts))\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cace3a-75f0-49e6-9095-1bc5048871b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Prompt construction\n",
    "# -----------------------------\n",
    "def build_step_instruction(select_item: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    The ONLY thing we add at current step:\n",
    "      - task instruction\n",
    "      - candidate tickers list\n",
    "      - market snapshot (7-day window)\n",
    "      - strict JSON output spec\n",
    "    \"\"\"\n",
    "    step = select_item[\"step\"]\n",
    "    date = select_item.get(\"date\", \"\")\n",
    "    snapshot = select_item[\"market_snapshot\"]\n",
    "    tickers = list(snapshot.keys())\n",
    "\n",
    "    content = f\"\"\"\n",
    "You are a personalized investment advisor.\n",
    "\n",
    "Task:\n",
    "Based on the FULL conversation above, which includes interactions between\n",
    "the user and multiple advisors offering different investment perspectives,\n",
    "infer the user's latent risk preference from their stated goals, emotional\n",
    "reactions, and responses to these perspectives.\n",
    "\n",
    "Then, using the current 7-day market snapshot, produce a personalized ranked\n",
    "list of ALL candidate stocks from best to worst for this user.\n",
    "\n",
    "Important:\n",
    "- The conversation may include advisory viewpoints reflecting different\n",
    "  principles (e.g., return-seeking, risk-averse, or balanced strategies).\n",
    "- These viewpoints may be complementary or conflicting.\n",
    "- Your goal is NOT to follow any advisor directly, but to infer which types\n",
    "  of advice best align with THIS user's preferences as revealed through\n",
    "  the conversation.\n",
    "- The user's risk preference is NOT given explicitly and must be inferred\n",
    "  from the conversation history.\n",
    "\n",
    "Candidates (must include all, exactly once):\n",
    "{tickers}\n",
    "\n",
    "Current market snapshot (7-day window):\n",
    "{format_market_snapshot(snapshot)}\n",
    "\n",
    "Output format (STRICT):\n",
    "Return a VALID JSON object with exactly ONE key:\n",
    "- \"final_rank\": a list of tickers ordered from best to worst.\n",
    "\n",
    "Format example (for structure only, NOT actual output):\n",
    "{{\n",
    "  \"final_rank\": [\"TICKER_1\", \"TICKER_2\",..., \"TICKER_10\"]\n",
    "}}\n",
    "\n",
    "Constraints:\n",
    "- \"final_rank\" MUST be a permutation of the candidate list above.\n",
    "- The list length MUST be exactly {len(tickers)}.\n",
    "- No duplicate tickers.\n",
    "- No missing tickers.\n",
    "- Do NOT include any other keys.\n",
    "- Do NOT include explanations or text outside the JSON.\n",
    "- Do NOT use markdown or code fences.\n",
    "\"\"\"\n",
    "\n",
    "    return {\"role\": \"user\", \"content\": content}\n",
    "\n",
    "def messages_to_prompt_text(messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"\n",
    "    Optional: also store a flat prompt string for non-chat inference pipelines.\n",
    "    Keeping both is convenient for HF users.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    for m in messages:\n",
    "        role = (m.get(\"role\") or \"\").upper()\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        chunks.append(f\"[{role}]\\n{content}\")\n",
    "    return \"\\n\\n\".join(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f0a3d8-7743-4dc8-b83c-5a40ae064502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Labels\n",
    "# -----------------------------\n",
    "def build_labels(select_item: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    ap = select_item[\"advisor_panel\"]\n",
    "    return {\n",
    "        \"utility_rank\": ap[\"utility_advisor\"][\"rank\"],\n",
    "        \"momentum_rank\": ap[\"momentum_advisor\"][\"rank\"],\n",
    "        \"safety_rank\": ap[\"safety_advisor\"][\"rank\"],\n",
    "        \"user_choice\": select_item[\"user_turn\"][\"choice\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be722560-7579-405e-a354-55258abef383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main dataset builder\n",
    "# -----------------------------\n",
    "def build_eval_records_for_user(\n",
    "    user_id: str,\n",
    "    history_path: str,\n",
    "    select_path: str,\n",
    "    *,\n",
    "    store_prompt_text: bool = True,\n",
    "    keep_marker_msg: bool = True,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    history = load_json(history_path)\n",
    "    select_data = load_json(select_path)\n",
    "\n",
    "    onboarding, post = split_onboarding(history)\n",
    "\n",
    "    marker_msg = {\"role\": \"system\", \"content\": MARKER}\n",
    "\n",
    "    records = []\n",
    "    for item in select_data:  # steps 1..23\n",
    "        t = int(item[\"step\"])\n",
    "\n",
    "        past_msgs = slice_post_history_for_step(post, t)\n",
    "\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        messages.extend(onboarding)\n",
    "        if keep_marker_msg:\n",
    "            messages.append(marker_msg)\n",
    "        messages.extend(past_msgs)\n",
    "\n",
    "        # append current step instruction + snapshot\n",
    "        messages.append(build_step_instruction(item))\n",
    "\n",
    "        rec: Dict[str, Any] = {\n",
    "            \"id\": f\"{user_id}_step_{t}\",\n",
    "            \"user_id\": user_id,\n",
    "            \"step\": t,\n",
    "            \"date\": item.get(\"date\", \"\"),\n",
    "            \"messages\": messages,  # <-- main prompt input (conversation)\n",
    "            \"labels\": build_labels(item),\n",
    "            \"meta\": {\n",
    "                \"candidate_tickers\": list(item[\"market_snapshot\"].keys()),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # optional convenience field for non-chat inference\n",
    "        if store_prompt_text:\n",
    "            rec[\"prompt\"] = messages_to_prompt_text(messages)\n",
    "\n",
    "        records.append(rec)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca7824b-2779-4e24-ba24-4642d7442376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_discover_users(data_dir: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Discover users by finding *_conversation_history.json and matching *_conversation_select.json.\n",
    "    Returns user_ids like 'User_0', 'User_1', ...\n",
    "    \"\"\"\n",
    "    history_files = glob.glob(os.path.join(data_dir, \"*_conversation_history.json\"))\n",
    "    user_ids = []\n",
    "    for hp in sorted(history_files):\n",
    "        base = os.path.basename(hp)\n",
    "        user_id = base.replace(\"_conversation_history.json\", \"\")\n",
    "        sp = os.path.join(data_dir, f\"{user_id}_conversation_select.json\")\n",
    "        if os.path.exists(sp):\n",
    "            user_ids.append(user_id)\n",
    "    return user_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546f833-e290-4d5c-bf9b-071741df32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_jsonl(\n",
    "    data_dir: str,\n",
    "    out_jsonl_path: str,\n",
    "    *,\n",
    "    user_ids: Optional[List[str]] = None,\n",
    "    store_prompt_text: bool = True,\n",
    "    keep_marker_msg: bool = True,\n",
    ") -> None:\n",
    "    if user_ids is None:\n",
    "        user_ids = auto_discover_users(data_dir)\n",
    "    if not user_ids:\n",
    "        raise ValueError(\"No users discovered. Expected files like User_0_conversation_history.json in data_dir.\")\n",
    "\n",
    "    all_records: List[Dict[str, Any]] = []\n",
    "    for user_id in user_ids:\n",
    "        history_path = os.path.join(data_dir, f\"{user_id}_conversation_history.json\")\n",
    "        select_path = os.path.join(data_dir, f\"{user_id}_conversation_select.json\")\n",
    "        if not os.path.exists(history_path):\n",
    "            raise FileNotFoundError(history_path)\n",
    "        if not os.path.exists(select_path):\n",
    "            raise FileNotFoundError(select_path)\n",
    "\n",
    "        recs = build_eval_records_for_user(\n",
    "            user_id=user_id,\n",
    "            history_path=history_path,\n",
    "            select_path=select_path,\n",
    "            store_prompt_text=store_prompt_text,\n",
    "            keep_marker_msg=keep_marker_msg,\n",
    "        )\n",
    "        all_records.extend(recs)\n",
    "\n",
    "    save_jsonl(all_records, out_jsonl_path)\n",
    "    print(f\"[OK] Wrote {len(all_records)} records to {out_jsonl_path}\")\n",
    "    print(f\"[OK] Users: {len(user_ids)} | Steps per user: {len(all_records)//len(user_ids) if user_ids else 'NA'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce12e990-ad77-40b9-86e7-a0606e9bc1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Notebook entry ===\n",
    "\n",
    "data_dir = \"user_conversation/\"   # Change to your actual path\n",
    "out_jsonl_path = \"evaluation/conv_finre_eval_10users.jsonl\"\n",
    "\n",
    "# If you want to automatically discover User_0 ... User_9\n",
    "user_ids = None\n",
    "\n",
    "\n",
    "build_eval_jsonl(\n",
    "    data_dir=data_dir,\n",
    "    out_jsonl_path=out_jsonl_path,\n",
    "    user_ids=user_ids,\n",
    "    store_prompt_text=True,   \n",
    "    keep_marker_msg=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a75b5-d526-4def-b30f-2348ed6c6c48",
   "metadata": {},
   "source": [
    "## build prompt without history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a96d7-ea5c-4d95-985d-79bbadfe4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Prompt construction (NO-HISTORY)\n",
    "# -----------------------------\n",
    "def build_step_instruction_no_history(select_item: Dict[str, Any]) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Current step message that ONLY uses:\n",
    "      - onboarding conversation (already above)\n",
    "      - current market snapshot\n",
    "    No post-onboarding history is included.\n",
    "    \"\"\"\n",
    "    step = int(select_item[\"step\"])\n",
    "    date = select_item.get(\"date\", \"\")\n",
    "    snapshot = select_item[\"market_snapshot\"]\n",
    "    tickers = list(snapshot.keys())\n",
    "\n",
    "    content = f\"\"\"\n",
    "You are a personalized investment advisor.\n",
    "\n",
    "Task:\n",
    "Based ONLY on the onboarding conversation above (user profile, goals, constraints, and risk attitude),\n",
    "and the current 7-day market snapshot, produce a personalized ranked list of ALL candidate stocks\n",
    "from best to worst for this user.\n",
    "\n",
    "Important:\n",
    "- Do NOT assume you have access to any post-onboarding interaction history.\n",
    "- Use only the onboarding information to infer the user's preferences.\n",
    "\n",
    "Candidates (must include all, exactly once):\n",
    "{tickers}\n",
    "\n",
    "Current market snapshot (7-day window) at step {step}{f\" on {date}\" if date else \"\"}:\n",
    "{format_market_snapshot(snapshot)}\n",
    "\n",
    "Output format (STRICT):\n",
    "Return a VALID JSON object with exactly ONE key:\n",
    "- \"final_rank\": a list of tickers ordered from best to worst.\n",
    "\n",
    "Format example (for structure only, NOT actual output):\n",
    "{{\n",
    "  \"final_rank\": [\"TICKER_1\", \"TICKER_2\",..., \"TICKER_10\"]\n",
    "}}\n",
    "\n",
    "Constraints:\n",
    "- \"final_rank\" MUST be a permutation of the candidate list above.\n",
    "- The list length MUST be exactly {len(tickers)}.\n",
    "- No duplicate tickers.\n",
    "- No missing tickers.\n",
    "- Do NOT include any other keys.\n",
    "- Do NOT include explanations or text outside the JSON.\n",
    "- Do NOT use markdown or code fences.\n",
    "\"\"\"\n",
    "    return {\"role\": \"user\", \"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64fa37-ab98-4f86-a238-8dbd4dc6f6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Main dataset builder (NO-HISTORY)\n",
    "# -----------------------------\n",
    "def build_eval_records_for_user_no_history(\n",
    "    user_id: str,\n",
    "    history_path: str,\n",
    "    select_path: str,\n",
    "    *,\n",
    "    store_prompt_text: bool = True,\n",
    "    keep_marker_msg: bool = True,\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Build records that contain ONLY:\n",
    "      - onboarding conversation\n",
    "      - (optional) marker system msg\n",
    "      - current step instruction with market snapshot\n",
    "    \"\"\"\n",
    "    history = load_json(history_path)\n",
    "    select_data = load_json(select_path)\n",
    "\n",
    "    onboarding, _post = split_onboarding(history)\n",
    "    marker_msg = {\"role\": \"system\", \"content\": MARKER}\n",
    "\n",
    "    records = []\n",
    "    for item in select_data:  # steps 1..T\n",
    "        t = int(item[\"step\"])\n",
    "\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        messages.extend(onboarding)\n",
    "        if keep_marker_msg:\n",
    "            messages.append(marker_msg)\n",
    "\n",
    "        # only current step instruction + snapshot\n",
    "        messages.append(build_step_instruction_no_history(item))\n",
    "\n",
    "        rec: Dict[str, Any] = {\n",
    "            \"id\": f\"{user_id}_step_{t}\",\n",
    "            \"user_id\": user_id,\n",
    "            \"step\": t,\n",
    "            \"date\": item.get(\"date\", \"\"),\n",
    "            \"messages\": messages,\n",
    "            \"labels\": build_labels(item),\n",
    "            \"meta\": {\n",
    "                \"candidate_tickers\": list(item[\"market_snapshot\"].keys()),\n",
    "                \"setting\": \"no_history_onboarding_plus_snapshot\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "        if store_prompt_text:\n",
    "            rec[\"prompt\"] = messages_to_prompt_text(messages)\n",
    "\n",
    "        records.append(rec)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd17b70-0386-41cb-9749-2f539b5ae399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_eval_jsonl_no_history(\n",
    "    data_dir: str,\n",
    "    out_jsonl_path: str,\n",
    "    *,\n",
    "    user_ids: Optional[List[str]] = None,\n",
    "    store_prompt_text: bool = True,\n",
    "    keep_marker_msg: bool = True,\n",
    ") -> None:\n",
    "    if user_ids is None:\n",
    "        user_ids = auto_discover_users(data_dir)\n",
    "    if not user_ids:\n",
    "        raise ValueError(\"No users discovered. Expected files like User_0_conversation_history.json in data_dir.\")\n",
    "\n",
    "    all_records: List[Dict[str, Any]] = []\n",
    "    for user_id in user_ids:\n",
    "        history_path = os.path.join(data_dir, f\"{user_id}_conversation_history.json\")\n",
    "        select_path = os.path.join(data_dir, f\"{user_id}_conversation_select.json\")\n",
    "        if not os.path.exists(history_path):\n",
    "            raise FileNotFoundError(history_path)\n",
    "        if not os.path.exists(select_path):\n",
    "            raise FileNotFoundError(select_path)\n",
    "\n",
    "        recs = build_eval_records_for_user_no_history(\n",
    "            user_id=user_id,\n",
    "            history_path=history_path,\n",
    "            select_path=select_path,\n",
    "            store_prompt_text=store_prompt_text,\n",
    "            keep_marker_msg=keep_marker_msg,\n",
    "        )\n",
    "        all_records.extend(recs)\n",
    "\n",
    "    save_jsonl(all_records, out_jsonl_path)\n",
    "    print(f\"[OK] Wrote {len(all_records)} records to {out_jsonl_path}\")\n",
    "    print(f\"[OK] Users: {len(user_ids)} | Steps per user: {len(all_records)//len(user_ids) if user_ids else 'NA'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bab6757-a5a3-4b89-ba18-209a04028429",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"user_conversation/\"\n",
    "out_jsonl_path = \"evaluation/conv_finre_eval_no_history_10users.jsonl\"\n",
    "\n",
    "\n",
    "user_ids = None\n",
    "\n",
    "\n",
    "build_eval_jsonl_no_history(\n",
    "    data_dir=data_dir,\n",
    "    out_jsonl_path=out_jsonl_path,\n",
    "    user_ids=user_ids,\n",
    "    store_prompt_text=True,\n",
    "    keep_marker_msg=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476d830-dc77-4b66-aa0f-bb988bb91f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-jupyter",
   "language": "python",
   "name": "jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
